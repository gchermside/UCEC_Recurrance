{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCEC Reccurance Notebook - Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data from ucec_tcga_pan_can_atlas_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import config\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TODO: Impliment these models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_df = pd.read_csv(\"ucec_tcga_pan_can_atlas_2018/data_mrna_seq_v2_rsem_zscores_ref_all_samples.txt\", sep=\"\\t\", comment=\"#\")\n",
    "# I appear to have 527 patients in the mRNA and 529 patients in the clinical data\n",
    "\n",
    "clinical_df = pd.read_csv(\"ucec_tcga_pan_can_atlas_2018\\data_clinical_patient.txt\", sep=\"\\t\", comment=\"#\", low_memory=False)\n",
    "clinical_df = clinical_df.set_index('PATIENT_ID')\n",
    "\n",
    "# The first 2 columns of the mRNA data are labels. 13 of the genes do not have Hugo_symbols, so I am putting placeholder stings as labels for these genes\n",
    "missing_symbols = mrna_df['Hugo_Symbol'].isnull()\n",
    "mrna_df.loc[missing_symbols, 'Hugo_Symbol'] = [\n",
    "    f'no_symbol_{i+1}' for i in range(missing_symbols.sum())\n",
    "]\n",
    "\n",
    "# Get value counts\n",
    "counts = mrna_df['Hugo_Symbol'].value_counts()\n",
    "\n",
    "# Generate unique labels for duplicates\n",
    "def label_duplicates(value, index):\n",
    "    if counts[value] == 1:\n",
    "        return value  # Keep unique values unchanged\n",
    "    occurrence = mrna_df.groupby('Hugo_Symbol').cumcount() + 1  # Count occurrences per group\n",
    "    return f\"{value}-{occurrence[index]}-of-{counts[value]}\"\n",
    "\n",
    "# Apply the labeling function\n",
    "mrna_df['Hugo_Symbol'] = [label_duplicates(value, idx) for idx, value in mrna_df['Hugo_Symbol'].items()]\n",
    "\n",
    "mrna_df = mrna_df.set_index('Hugo_Symbol')\n",
    "mrna_df = mrna_df.drop(columns=\"Entrez_Gene_Id\") # removing the label column before I transpose the df\n",
    "mrna_df_transposed= mrna_df.transpose()\n",
    "mrna_df_transposed.index = [id[:-3] for id in mrna_df_transposed.index] # removes extranious -01 so that the patient ids match the clinical data\n",
    "\n",
    "df = clinical_df.join(mrna_df_transposed, how='inner') # this is the data frame for clinical and genetic data. It has 527 patients (rows) and 20568 features (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "-3.7272: 171\n",
      "-1.0: 1\n",
      "1.0: 1\n"
     ]
    }
   ],
   "source": [
    "#testing around\n",
    "df[\"FKSG73\"]\n",
    "unique_values = df[\"FKSG73\"].nunique(dropna=True)\n",
    "print(unique_values)\n",
    "\n",
    "counts = Counter(df[\"FKSG73\"].dropna())\n",
    "\n",
    "# Print unique values and their counts\n",
    "for item, count in counts.items():\n",
    "    print(f\"{item}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following genes appear in the data more than once but have different data: \n",
    "['PALM2AKAP2', 'ELMOD1', 'FGF13', 'QSOX1', 'SNAP47', 'NKAIN3', 'TMEM8B']\n",
    "Right now, I'm leaving every version of the gene in, but giving placeholder unique names like: PALM2AKAP2-1-of-2 and PALM2AKAP2-2-of-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unecessary columns from clinical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT             DFS_STATUS  Count\n",
      "0                                      No          0:DiseaseFree    326\n",
      "1                                      No  1:Recurred/Progressed     12\n",
      "2                                      No                    NaN     49\n",
      "3                                     Yes          0:DiseaseFree      7\n",
      "4                                     Yes  1:Recurred/Progressed     38\n",
      "5                                     Yes                    NaN     34\n",
      "6                                     NaN          0:DiseaseFree     24\n",
      "7                                     NaN  1:Recurred/Progressed      5\n",
      "8                                     NaN                    NaN     32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def assign_label(row):\n",
    "    '''given a row assigns 1 for recurrance and 0 for no recurrance. \n",
    "    Currently uses NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT to identify recurrance.\n",
    "    If NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT is NaN, uses DSF_STATUS'''\n",
    "    if row['NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT'] == 'Yes':\n",
    "        return 1\n",
    "    elif row['NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT'] == 'No':\n",
    "        return 0\n",
    "    elif pd.isna(row['NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT']):\n",
    "        if row['DFS_STATUS'] == '1:Recurred/Progressed':\n",
    "            return 1\n",
    "        elif row['DFS_STATUS'] == '0:DiseaseFree':\n",
    "            return 0\n",
    "        else:\n",
    "            raise ValueError(f\"Error: Both columns are NaN at index {row.name}\")\n",
    "\n",
    "def drop_highly_uniform_columns(df, threshold=0.99):\n",
    "    \"\"\"\n",
    "    Drops columns where more than 'threshold' proportion of non-NaN values are the same.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - threshold: float (default 0.99), proportion threshold to drop columns\n",
    "\n",
    "    Returns:\n",
    "    - pandas DataFrame with specified columns dropped\n",
    "    \"\"\"\n",
    "    cols_to_drop = []\n",
    "    for col in df.columns:\n",
    "        non_na_values = df[col].dropna()\n",
    "        if not non_na_values.empty:\n",
    "            top_freq = non_na_values.value_counts(normalize=True).iloc[0]\n",
    "            if top_freq > threshold:\n",
    "                cols_to_drop.append(col)\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "drop_highly_uniform_columns(df)\n",
    "\n",
    "# remove the column if over MAX_NULL_VALS percent null values\n",
    "df = df.dropna(axis=1, thresh=len(df) * (1 - config.MAX_NULL_VALS))\n",
    "\n",
    "# remove non-informational columns\n",
    "df = df.drop(columns=['OTHER_PATIENT_ID'])\n",
    "\n",
    "# Just used for looking at the data for the labels\n",
    "pair_counts = df.groupby([\"NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT\", 'DFS_STATUS'], dropna=False).size().reset_index(name='Count')\n",
    "\n",
    "# Print the pairings and the count\n",
    "print(pair_counts)\n",
    "\n",
    "# I am going to remove the 32 rows where we have no recurrance label (neither NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT nor DFS_STATUS are known)\n",
    "# PFS_STATUS\n",
    "df = df.dropna(subset=['DFS_STATUS', 'NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT'], how='all')\n",
    "\n",
    "# # numpy array for the Labels for recurrance\n",
    "labels = np.array(df.apply(assign_label, axis=1)) \n",
    "#DIF DFI.time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms data by changing catagorical data into numerical data and filling in missing data points with medians or modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values:\n",
      "SUBTYPE                                     19\n",
      "AGE                                          2\n",
      "AJCC_STAGING_EDITION                        69\n",
      "DAYS_LAST_FOLLOWUP                          33\n",
      "DAYS_TO_BIRTH                                3\n",
      "DAYS_TO_INITIAL_PATHOLOGIC_DIAGNOSIS         5\n",
      "ETHNICITY                                  146\n",
      "NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT     29\n",
      "PERSON_NEOPLASM_CANCER_STATUS               24\n",
      "RACE                                        30\n",
      "RADIATION_THERAPY                            6\n",
      "WEIGHT                                      20\n",
      "DSS_STATUS                                   2\n",
      "DFS_STATUS                                  83\n",
      "DFS_MONTHS                                  83\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = df.isnull().sum()\n",
    "nonzero_nans = nan_counts[nan_counts > 0]\n",
    "print(\"Columns with NaN values:\")\n",
    "print(nonzero_nans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGE', 'AJCC_STAGING_EDITION', 'DAYS_TO_BIRTH',\n",
      "       'DAYS_TO_INITIAL_PATHOLOGIC_DIAGNOSIS', 'WEIGHT', 'no_symbol_2',\n",
      "       'UBE2Q2P2', 'HMGB1P1', 'no_symbol_3', 'no_symbol_5',\n",
      "       ...\n",
      "       'RADIATION_THERAPY_Yes', 'IN_PANCANPATHWAYS_FREEZE_Yes',\n",
      "       'GENETIC_ANCESTRY_LABEL_ADMIX', 'GENETIC_ANCESTRY_LABEL_AFR',\n",
      "       'GENETIC_ANCESTRY_LABEL_AFR_ADMIX', 'GENETIC_ANCESTRY_LABEL_AMR',\n",
      "       'GENETIC_ANCESTRY_LABEL_EAS', 'GENETIC_ANCESTRY_LABEL_EUR',\n",
      "       'GENETIC_ANCESTRY_LABEL_EUR_ADMIX', 'GENETIC_ANCESTRY_LABEL_SAS'],\n",
      "      dtype='object', length=17531)\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = [\"ETHNICITY\",\n",
    "                        \"ICD_10\", \n",
    "                        \"PRIOR_DX\", \n",
    "                        \"RACE\",\n",
    "                        \"RADIATION_THERAPY\", \n",
    "                        \"IN_PANCANPATHWAYS_FREEZE\", \n",
    "                        \"GENETIC_ANCESTRY_LABEL\"] #FIXME: do further research on what ICD_10 and ICD_O_3_SITE are\n",
    "\n",
    "# Fill numerical NaNs with median\n",
    "numerical_df = df.select_dtypes(include=['number'])\n",
    "numerical_df = numerical_df.drop(columns=['OS_MONTHS', 'DSS_MONTHS', 'DFS_MONTHS', 'PFS_MONTHS'])\n",
    "numerical_df = numerical_df.fillna(numerical_df.median())\n",
    "\n",
    "# fill catagorical columns with mode\n",
    "categorical_df = df[categorical_columns]\n",
    "categorical_df = categorical_df.fillna(categorical_df.mode())\n",
    "\n",
    "\n",
    "# One-Hot Encode categorical columns (drop first to avoid redundancy)\n",
    "categorical_df = pd.get_dummies(categorical_df, drop_first=True, dtype=float)\n",
    "\n",
    "X = pd.concat([numerical_df, categorical_df], axis=1)\n",
    "print((X.columns))\n",
    "# feature_names = {i: col for i, col in enumerate(X.columns)}\n",
    "feature_names = X.columns\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving my split of training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/y_test.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=1, stratify=labels)\n",
    "\n",
    "joblib.dump(X_train, config.X_TRAIN_PATH)\n",
    "joblib.dump(X_test, config.X_TEST_PATH)\n",
    "joblib.dump(y_train, config.Y_TRAIN_PATH)\n",
    "joblib.dump(y_test, config.Y_TEST_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
