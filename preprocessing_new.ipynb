{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2b8de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e03adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the mRNA and clinical data:\n",
    "clinical_df = pd.read_csv(\"ucec_tcga_pan_can_atlas_2018\\data_clinical_patient.txt\", sep=\"\\t\", comment=\"#\", low_memory=False)\n",
    "clinical_df = clinical_df.set_index('PATIENT_ID')\n",
    "\n",
    "mrna_df = pd.read_csv(\"ucec_tcga_pan_can_atlas_2018/data_mrna_seq_v2_rsem_zscores_ref_all_samples.txt\", sep=\"\\t\", comment=\"#\")\n",
    "\n",
    "# There are 527 patients in the mRNA and 529 patients in the clinical data\n",
    "\n",
    "# The first 2 columns of the mRNA data are labels (Hugo_Symbol then Entrez_Gene_Id). \n",
    "# 13 of the genes do not have Hugo_symbols, so for these I will you the Entrex_Gene_Id as the label.\n",
    "missing_symbols = mrna_df['Hugo_Symbol'].isnull()\n",
    "mrna_df.loc[missing_symbols, 'Hugo_Symbol'] = mrna_df.loc[missing_symbols, 'Entrez_Gene_Id'].astype(str)\n",
    "\n",
    "# There are 7 rows that have both the same Hugo_Symbol and Entrez_Gene_Id but different values for the patients.\n",
    "# I will rename these rows to have unique labels by appending -1-of-2 and -2-of-2 to the Hugo_Symbol.\n",
    "# Get value counts\n",
    "counts = mrna_df['Hugo_Symbol'].value_counts()\n",
    "\n",
    "# Generate unique labels for duplicates\n",
    "def label_duplicates(value, index):\n",
    "    if counts[value] == 1:\n",
    "        return value  # Keep unique values unchanged\n",
    "    occurrence = mrna_df.groupby('Hugo_Symbol').cumcount() + 1  # Count occurrences per group\n",
    "    return f\"{value}-{occurrence[index]}-of-{counts[value]}\"\n",
    "\n",
    "# Apply the labeling function\n",
    "mrna_df['Hugo_Symbol'] = [label_duplicates(value, idx) for idx, value in mrna_df['Hugo_Symbol'].items()]\n",
    "\n",
    "mrna_df = mrna_df.set_index('Hugo_Symbol')\n",
    "mrna_df = mrna_df.drop(columns=\"Entrez_Gene_Id\") # removing the label column before I transpose the df\n",
    "mrna_df= mrna_df.transpose() # now the patients are the index and the genes are the columns\n",
    "mrna_df.index = [id[:-3] for id in mrna_df.index] # removes extranious -01 so that the patient ids match the clinical data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ea5b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_labels(clinical_df):\n",
    "    '''given the clinical dataframe, returns the corresposnding labels, \n",
    "    assigning 1 for recurrance, 0 for no recurrance, \n",
    "    and None if the patient has no recurrence information. \n",
    "    Currently uses NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT to identify recurrance.\n",
    "    If NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT is NaN, uses DSF_STATUS to save the label.'''\n",
    "    labels = []\n",
    "    for _, row in clinical_df.iterrows():\n",
    "        if row['NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT'] == 'Yes':\n",
    "            labels.append(1)\n",
    "        elif row['NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT'] == 'No':\n",
    "            labels.append(0)\n",
    "        elif pd.isna(row['NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT']):\n",
    "            if row['DFS_STATUS'] == '1:Recurred/Progressed':\n",
    "                labels.append(1)\n",
    "            elif row['DFS_STATUS'] == '0:DiseaseFree':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(None)\n",
    "    return pd.Series(labels, index=clinical_df.index)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def drop_patients_missing_data(clinical_df, mrna_df, labels):\n",
    "    '''Drops patients from both dataframes that are not present in the other dataframe. \n",
    "    Drops patients who are missing labeling data used to define recurrence.\n",
    "    Returns the cleaned dataframes and labels.'''\n",
    "    # Find patient IDs not shared between the two dataframes:\n",
    "    clinical_not_in_mrna = set(clinical_df.index) - set(mrna_df.index)\n",
    "    mrna_not_in_clinical = set(mrna_df.index) - set(clinical_df.index)\n",
    "    # There are 2 patients ('TCGA-EY-A1GJ', 'TCGA-AP-A0LQ') in the clinical data that are not in the mRNA data.\n",
    "    clinical_df = clinical_df.drop(index=clinical_not_in_mrna)\n",
    "    mrna_df = mrna_df.drop(index=mrna_not_in_clinical)\n",
    "    labels = labels.drop(index=clinical_not_in_mrna)\n",
    "    labels = labels.drop(index=mrna_not_in_clinical)\n",
    "    assert clinical_df.shape[0] == mrna_df.shape[0] == labels.shape[0], \"Dataframes have different number of patients after cleaning\"\n",
    "\n",
    "    # Now drop patients missing labeling data used to define recurrence:\n",
    "    patients_no_label = labels[labels.isna()].index\n",
    "    clinical_df = clinical_df.drop(index=patients_no_label)\n",
    "    mrna_df = mrna_df.drop(index=patients_no_label)\n",
    "    labels = labels.drop(index=patients_no_label)\n",
    "    assert not labels.isna().any(), \"Found unlabeled patient after cleaning\"\n",
    "\n",
    "    return clinical_df, mrna_df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7df8ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_post_diagnosis_clinical_columns(clinical_df):\n",
    "    '''Removes all columns in the clinical data that are recurrence indicators or are not available at diagnosis.\n",
    "    Returns the cleaned clinical dataframe and the labels series.'''\n",
    "    cols_to_drop = [\n",
    "    \"DAYS_LAST_FOLLOWUP\",              # follow-up time after diagnosis (future info)\n",
    "    \"FORM_COMPLETION_DATE\",            # administrative metadata, not predictive\n",
    "    \"INFORMED_CONSENT_VERIFIED\",       # administrative, no biological meaning\n",
    "    \"NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT\",  # recurrence event → direct leakage\n",
    "    \"PERSON_NEOPLASM_CANCER_STATUS\",   # disease status at follow-up → leakage\n",
    "    \"IN_PANCANPATHWAYS_FREEZE\",        # technical/analysis flag, not biological\n",
    "    \"OS_STATUS\",                       # overall survival outcome → leakage\n",
    "    \"OS_MONTHS\",                       # overall survival time → leakage\n",
    "    \"DSS_STATUS\",                      # disease-specific survival outcome → leakage\n",
    "    \"DSS_MONTHS\",                      # disease-specific survival time → leakage\n",
    "    \"DFS_STATUS\",                      # disease-free survival outcome → leakage\n",
    "    \"DFS_MONTHS\",                      # disease-free survival time → leakage\n",
    "    \"PFS_STATUS\",                      # progression-free survival outcome → leakage\n",
    "    \"PFS_MONTHS\"                       # progression-free survival time → leakage\n",
    "]\n",
    "    clinical_df = clinical_df.drop(columns=cols_to_drop)\n",
    "    return clinical_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test(clinical_df, mrna_df, labels, test_size=0.2, random_state=1):\n",
    "    \"\"\"\n",
    "    Splits clinical and mRNA data into train/test sets using precomputed labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clinical_df : pd.DataFrame\n",
    "        Clinical features (indexed by patient ID).\n",
    "    mrna_df : pd.DataFrame\n",
    "        mRNA expression features (indexed by patient ID).\n",
    "    labels : pd.Series\n",
    "        Precomputed labels indexed by patient ID.\n",
    "    test_size : float\n",
    "        Fraction of patients to hold out for testing.\n",
    "    random_state : int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict of train/test splits:\n",
    "        {\n",
    "            \"X_clinical_train\", \"X_clinical_test\",\n",
    "            \"X_mrna_train\", \"X_mrna_test\",\n",
    "            \"y_train\", \"y_test\"\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # Train/test split on patient IDs\n",
    "    train_ids, test_ids = train_test_split(\n",
    "        labels.index,\n",
    "        test_size=test_size,\n",
    "        stratify=labels,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Slice dataframes and labels\n",
    "    splits = {\n",
    "        \"X_clinical_train\": clinical_df.loc[train_ids],\n",
    "        \"X_clinical_test\":  clinical_df.loc[test_ids],\n",
    "        \"X_mrna_train\":     mrna_df.loc[train_ids],\n",
    "        \"X_mrna_test\":      mrna_df.loc[test_ids],\n",
    "        \"y_train\":          labels.loc[train_ids],\n",
    "        \"y_test\":           labels.loc[test_ids]\n",
    "    }\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7af21cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_clinical_features(X_train, X_test, categorical_cols=None, ordinal_cols=None, ordinal_mappings=None):\n",
    "    \"\"\"\n",
    "    Encode clinical features: one-hot for categorical, ordinal for ordinal columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training clinical features.\n",
    "    X_test : pd.DataFrame\n",
    "        Test clinical features.\n",
    "    categorical_cols : list of str\n",
    "        Columns to one-hot encode.\n",
    "    ordinal_cols : list of str\n",
    "        Columns to ordinally encode.\n",
    "    ordinal_mappings : dict\n",
    "        Mapping of column name -> list of categories in order for ordinal encoding.\n",
    "        Example: {'TUMOR_GRADE': ['G1', 'G2', 'G3']}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train_encoded, X_test_encoded : pd.DataFrame, pd.DataFrame\n",
    "        Encoded training and test clinical dataframes.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_test_encoded = X_test.copy()\n",
    "\n",
    "    # --- One-hot encode categorical columns ---\n",
    "    if categorical_cols:\n",
    "        ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        ohe_train = ohe.fit_transform(X_train_encoded[categorical_cols])\n",
    "        ohe_test  = ohe.transform(X_test_encoded[categorical_cols])\n",
    "\n",
    "        ohe_columns = ohe.get_feature_names_out(categorical_cols)\n",
    "        ohe_train_df = pd.DataFrame(ohe_train, columns=ohe_columns, index=X_train_encoded.index)\n",
    "        ohe_test_df  = pd.DataFrame(ohe_test, columns=ohe_columns, index=X_test_encoded.index)\n",
    "\n",
    "        X_train_encoded = pd.concat([X_train_encoded.drop(columns=categorical_cols), ohe_train_df], axis=1)\n",
    "        X_test_encoded  = pd.concat([X_test_encoded.drop(columns=categorical_cols), ohe_test_df], axis=1)\n",
    "\n",
    "    # --- Ordinal encode ordinal columns ---\n",
    "    if ordinal_cols:\n",
    "        if ordinal_mappings is None:\n",
    "            raise ValueError(\"You must provide ordinal_mappings when encoding ordinal columns.\")\n",
    "\n",
    "        for col in ordinal_cols:\n",
    "            encoder = OrdinalEncoder(categories=[ordinal_mappings[col]])\n",
    "            X_train_encoded[[col]] = encoder.fit_transform(X_train_encoded[[col]])\n",
    "            X_test_encoded[[col]]  = encoder.transform(X_test_encoded[[col]])\n",
    "\n",
    "    return X_train_encoded, X_test_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35b4572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClinicalPreprocessor:\n",
    "    def __init__(self, cols_to_remove, categorical_cols, max_null_frac=0.3, uniform_thresh=0.99):\n",
    "        self.cols_to_remove = cols_to_remove\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.max_null_frac = max_null_frac\n",
    "        self.uniform_thresh = uniform_thresh\n",
    "        \n",
    "        # Saved state after fit\n",
    "        self.removed_cols_ = []\n",
    "        self.columns_ = None  # final column order\n",
    "        self.num_fill_values_ = {}\n",
    "        self.cat_fill_values_ = {}\n",
    "    \n",
    "    def _drop_highly_uniform_columns(self, df):\n",
    "        \"\"\"Identifies highly uniform columns (> threshold same value).\"\"\"\n",
    "        cols_to_drop = []\n",
    "        for col in df.columns:\n",
    "            non_na_values = df[col].dropna()\n",
    "            if not non_na_values.empty:\n",
    "                top_freq = non_na_values.value_counts(normalize=True).iloc[0]\n",
    "                if top_freq > self.uniform_thresh:\n",
    "                    cols_to_drop.append(col)\n",
    "        return cols_to_drop\n",
    "    \n",
    "    def fit(self, df):\n",
    "        # --- Step 1. Drop specified columns\n",
    "        removed = [c for c in self.cols_to_remove if c in df.columns]\n",
    "        \n",
    "        # --- Step 2. Drop columns with too many nulls\n",
    "        thresh = len(df) * (1 - self.max_null_frac)\n",
    "        high_null_cols = [c for c in df.columns if df[c].isna().sum() > len(df) - thresh]\n",
    "        removed.extend(high_null_cols)\n",
    "        \n",
    "        # --- Step 3. Drop highly uniform columns\n",
    "        uniform_cols = self._drop_highly_uniform_columns(df)\n",
    "        removed.extend(uniform_cols)\n",
    "\n",
    "        # --- Step 4. Drop all identified columns\n",
    "        df = df.drop(columns=removed, errors=\"ignore\")\n",
    "        \n",
    "        # --- Step 5. Fill NaNs\n",
    "        # Numerical → median\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        self.num_fill_values_ = df[numeric_cols].median()\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(self.num_fill_values_)\n",
    "        \n",
    "        # Categorical → mode\n",
    "        cat_cols = [c for c in self.categorical_cols if c in df.columns]\n",
    "        self.cat_fill_values_ = {c: df[c].mode().iloc[0] for c in cat_cols if not df[c].dropna().empty}\n",
    "        for c, mode_val in self.cat_fill_values_.items():\n",
    "            df[c] = df[c].fillna(mode_val)\n",
    "        \n",
    "        # --- Step 6. One-hot encode categorical\n",
    "        df_enc = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "        \n",
    "        # Save results\n",
    "        self.removed_cols_ = removed\n",
    "        self.columns_ = df_enc.columns.tolist()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        # Drop removed cols\n",
    "        df = df.drop(columns=[c for c in self.removed_cols_ if c in df.columns], errors=\"ignore\")\n",
    "        \n",
    "        # --- Fill NaNs using training fill values\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        for c in numeric_cols:\n",
    "            if c in self.num_fill_values_:\n",
    "                df[c] = df[c].fillna(self.num_fill_values_[c])\n",
    "        \n",
    "        cat_cols = [c for c in self.categorical_cols if c in df.columns]\n",
    "        for c in cat_cols:\n",
    "            if c in self.cat_fill_values_:\n",
    "                df[c] = df[c].fillna(self.cat_fill_values_[c])\n",
    "        \n",
    "        # One-hot encode\n",
    "        df_enc = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "        \n",
    "        # Reindex to training columns (fill missing with 0)\n",
    "        df_enc = df_enc.reindex(columns=self.columns_, fill_value=0)\n",
    "        \n",
    "        return df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "143c6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MrnaPreprocessor:\n",
    "    def __init__(self, max_null_frac=0.3, uniform_thresh=0.99, corr_thresh=0.9, var_thresh=1e-5, literature_genes=set()):\n",
    "        self.max_null_frac = max_null_frac\n",
    "        self.uniform_thresh = uniform_thresh\n",
    "        self.corr_thresh = corr_thresh\n",
    "        self.var_thresh = var_thresh\n",
    "        self.literature_genes = literature_genes\n",
    "\n",
    "        # Saved state after fit\n",
    "        self.removed_cols_ = []\n",
    "        self.medians_ = {}\n",
    "        self.columns_ = None\n",
    "\n",
    "    def _drop_highly_uniform_columns(self, df):\n",
    "        \"\"\"Identify and drop highly uniform columns (> threshold).\"\"\"\n",
    "        cols_to_drop = []\n",
    "        for col in df.columns:\n",
    "            non_na_values = df[col].dropna()\n",
    "            if not non_na_values.empty:\n",
    "                top_freq = non_na_values.value_counts(normalize=True).iloc[0]\n",
    "                if top_freq > self.uniform_thresh:\n",
    "                    cols_to_drop.append(col)\n",
    "        return df.drop(columns=cols_to_drop), cols_to_drop\n",
    "\n",
    "    def _prune_correlated_features(self, df):\n",
    "        \"\"\"Prune correlated features above correlation threshold.\"\"\"\n",
    "        corr_matrix = df.corr().abs()\n",
    "        np.fill_diagonal(corr_matrix.values, 0)\n",
    "\n",
    "        high_corr_map = {\n",
    "            gene: set(corr_matrix.index[corr_matrix.loc[gene] >= self.corr_thresh])\n",
    "            for gene in corr_matrix.columns\n",
    "        }\n",
    "\n",
    "        genes_to_keep = set(corr_matrix.columns)\n",
    "        genes_to_remove = set()\n",
    "\n",
    "        while True:\n",
    "            correlated_genes = {g: nbrs for g, nbrs in high_corr_map.items() if nbrs & genes_to_keep}\n",
    "            if not correlated_genes:\n",
    "                break\n",
    "\n",
    "            degrees = {g: len(nbrs & genes_to_keep) for g, nbrs in correlated_genes.items() if g in genes_to_keep}\n",
    "            if not degrees:\n",
    "                break\n",
    "\n",
    "            worst_gene = max(degrees, key=lambda g: degrees[g])\n",
    "\n",
    "            if worst_gene in self.literature_genes:\n",
    "                neighbors = correlated_genes[worst_gene] & genes_to_keep\n",
    "                non_lit_neighbors = [n for n in neighbors if n not in self.literature_genes]\n",
    "                if non_lit_neighbors:\n",
    "                    worst_gene = min(non_lit_neighbors, key=lambda n: df[n].var())\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                ties = [g for g, d in degrees.items() if d == degrees[worst_gene]]\n",
    "                if len(ties) > 1:\n",
    "                    worst_gene = min(ties, key=lambda g: df[g].var())\n",
    "            \n",
    "            genes_to_remove.add(worst_gene)\n",
    "            genes_to_keep.remove(worst_gene)\n",
    "\n",
    "        return df[list(genes_to_keep)], genes_to_remove\n",
    "\n",
    "\n",
    "    def fit(self, df):\n",
    "        removed = []\n",
    "\n",
    "        # Step 1. Drop columns with too many nulls\n",
    "        high_null_cols = [c for c in df.columns if df[c].isna().sum() > len(df) * self.max_null_frac]\n",
    "        removed.extend(high_null_cols)\n",
    "        df_temp = df.drop(columns=high_null_cols, errors=\"ignore\")\n",
    "        print(f\"Dropped {len(high_null_cols)} columns with >{self.max_null_frac*100}% nulls\")\n",
    "\n",
    "        # Step 2. Drop highly uniform columns\n",
    "        df_temp, uniform_cols = self._drop_highly_uniform_columns(df_temp)\n",
    "        removed.extend(uniform_cols)\n",
    "        print(f\"Dropped {len(uniform_cols)} highly uniform columns\")\n",
    "\n",
    "        # Step 3. Fill NaNs with median\n",
    "        self.medians_ = df_temp.median().to_dict()\n",
    "        df_temp = df_temp.fillna(self.medians_)\n",
    "\n",
    "        # Step 4. Variance filter\n",
    "        low_var_cols = [c for c in df_temp.columns if df_temp[c].var() < self.var_thresh]\n",
    "        df_temp = df_temp.drop(columns=low_var_cols, errors=\"ignore\")\n",
    "        removed.extend(low_var_cols)\n",
    "        print(f\"Dropped {len(low_var_cols)} low variance columns (<{self.var_thresh})\")\n",
    "\n",
    "        # CHECKING TO SEE IF PRUNING IS HELPING OR HURTING\n",
    "        # # Step 5. Prune correlated features\n",
    "        # df_temp, correlated_genes = self._prune_correlated_features(df_temp)\n",
    "        # removed.extend(correlated_genes)\n",
    "        # print(f\"Dropped {len(correlated_genes)} correlated genes (>{self.corr_thresh} correlation)\")\n",
    "\n",
    "        # Save final state\n",
    "        self.removed_cols_ = list(set(removed))\n",
    "        self.columns_ = df_temp.columns.tolist()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        # Drop known removed cols\n",
    "        df = df.drop(columns=[c for c in self.removed_cols_ if c in df.columns])\n",
    "\n",
    "        # Fill NaNs with median\n",
    "        df = df.fillna(self.medians_)\n",
    "\n",
    "        # Check column alignment\n",
    "        missing = set(self.columns_) - set(df.columns)\n",
    "        extra = set(df.columns) - set(self.columns_)\n",
    "        if missing or extra:\n",
    "            raise ValueError(\n",
    "                f\"Column mismatch! Missing: {missing}, Extra: {extra}, \"\n",
    "                f\"{len(missing)} missing, {len(extra)} extra\"\n",
    "            )\n",
    "\n",
    "        # Reorder df to match training column order\n",
    "        df = df[self.columns_]\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9f8e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns: ['CANCER_TYPE_ACRONYM', 'OTHER_PATIENT_ID', 'SEX', 'AJCC_PATHOLOGIC_TUMOR_STAGE', 'DAYS_TO_INITIAL_PATHOLOGIC_DIAGNOSIS', 'HISTORY_NEOADJUVANT_TRTYN', 'PATH_M_STAGE', 'ICD_O_3_SITE', 'AJCC_PATHOLOGIC_TUMOR_STAGE', 'ETHNICITY', 'PATH_M_STAGE', 'PATH_N_STAGE', 'PATH_T_STAGE', 'PRIMARY_LYMPH_NODE_PRESENTATION_ASSESSMENT', 'CANCER_TYPE_ACRONYM', 'SEX', 'DAYS_TO_INITIAL_PATHOLOGIC_DIAGNOSIS', 'HISTORY_NEOADJUVANT_TRTYN']\n",
      "Dropped 3024 columns with >25.0% nulls\n",
      "Dropped 0 highly uniform columns\n",
      "Dropped 0 low variance columns (<1e-05)\n"
     ]
    }
   ],
   "source": [
    "labels = assign_labels(clinical_df)\n",
    "clinical_df, mrna_df, labels = drop_patients_missing_data(clinical_df, mrna_df, labels)\n",
    "clinical_df = drop_post_diagnosis_clinical_columns(clinical_df)\n",
    "splits = split_train_test(clinical_df, mrna_df, labels)\n",
    "\n",
    "clinical_train = splits[\"X_clinical_train\"]\n",
    "clinical_test  = splits[\"X_clinical_test\"]\n",
    "mrna_train     = splits[\"X_mrna_train\"]\n",
    "mrna_test      = splits[\"X_mrna_test\"]\n",
    "y_train          = splits[\"y_train\"]\n",
    "y_test           = splits[\"y_test\"]\n",
    "\n",
    "cols_to_remove = [\n",
    "    \"CANCER_TYPE_ACRONYM\",\n",
    "    \"OTHER_PATIENT_ID\",\n",
    "    \"SEX\",\n",
    "    \"AJCC_PATHOLOGIC_TUMOR_STAGE\",\n",
    "    \"DAYS_TO_INITIAL_PATHOLOGIC_DIAGNOSIS\",\n",
    "    \"HISTORY_NEOADJUVANT_TRTYN\",\n",
    "    \"PATH_M_STAGE\",\n",
    "    \"ICD_O_3_SITE\", # removed because is the same as ICD_10\n",
    "    \"ICD_O_3_\"\n",
    "]\n",
    "categorical_cols = ['SUBTYPE', \n",
    "                    'ETHNICITY', \n",
    "                    \"ICD_10\", \n",
    "                    \"ICD_O_3_HISTOLOGY\", \n",
    "                    \"PRIOR_DX\", \n",
    "                    \"RACE\", \n",
    "                    \"RADIATION_THERAPY\", \n",
    "                    \"GENETIC_ANCESTRY_LABEL\"\n",
    "]\n",
    "\n",
    "clinical_preproc = ClinicalPreprocessor(\n",
    "    cols_to_remove=cols_to_remove,\n",
    "    categorical_cols=categorical_cols,\n",
    "    max_null_frac=config.MAX_NULL_VALS,\n",
    "    uniform_thresh=config.UNIFORM_THRESHOLD\n",
    ")\n",
    "\n",
    "# Fit on train\n",
    "clinical_train = clinical_preproc.fit(clinical_train).transform(clinical_train)\n",
    "\n",
    "# Apply same preprocessing to test\n",
    "clinical_test = clinical_preproc.transform(clinical_test)\n",
    "\n",
    "# See which columns were dropped\n",
    "print(\"Removed columns:\", clinical_preproc.removed_cols_)\n",
    "\n",
    "mrna_preproc = MrnaPreprocessor(config.MAX_NULL_VALS,\n",
    "                                 config.UNIFORM_THRESHOLD,\n",
    "                                 config.CORRELATION_THRESHOLD,\n",
    "                                 config.VARIANCE_THRESHOLD,\n",
    "                                 literature_genes=config.LITERATURE_GENES)\n",
    "\n",
    "mrna_train = mrna_preproc.fit(mrna_train).transform(mrna_train)\n",
    "\n",
    "mrna_test = mrna_preproc.transform(mrna_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, I'm going to try to use the old clinical data, and see how that changes things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb9917e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed mRNA columns: 3024\n",
      "Final mRNA columns: 17507\n",
      "Length of X_test: 17529\n",
      "{'ICD_O_3_HISTOLOGY_8380/3', 'ICD_O_3_HISTOLOGY_8382/3', 'ICD_O_3_HISTOLOGY_8461/3', 'ICD_O_3_HISTOLOGY_8460/3', 'ICD_O_3_HISTOLOGY_8255/3', 'ICD_O_3_HISTOLOGY_8441/3', 'SUBTYPE_UCEC_CN_LOW', 'SUBTYPE_UCEC_MSI', 'SUBTYPE_UCEC_POLE', 'ICD_O_3_HISTOLOGY_8310/3'}\n",
      "{'GENETIC_ANCESTRY_LABEL_EUR_ADMIX', 'IN_PANCANPATHWAYS_FREEZE_Yes'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['new_data/y_test_no_prune.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Removed mRNA columns:\", len(mrna_preproc.removed_cols_))\n",
    "print(\"Final mRNA columns:\", len(mrna_preproc.columns_))\n",
    "\n",
    "X_train = clinical_train.join(mrna_train, how=\"inner\")\n",
    "X_test = clinical_test.join(mrna_test, how=\"inner\")\n",
    "\n",
    "old_X_train = joblib.load(config.X_TRAIN_PATH)\n",
    "print(\"Length of X_test:\", len(old_X_train.columns))\n",
    "\n",
    "print(set(X_train.columns) - set(old_X_train.columns))\n",
    "print(set(old_X_train.columns) - set(X_train.columns))\n",
    "\n",
    "joblib.dump(X_train, \"new_data/X_train_no_prune.pkl\")\n",
    "joblib.dump(X_test, \"new_data/X_test_no_prune.pkl\")\n",
    "joblib.dump(y_train, \"new_data/y_train_no_prune.pkl\")\n",
    "joblib.dump(y_test, \"new_data/y_test_no_prune.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
